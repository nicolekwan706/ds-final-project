# -*- coding: utf-8 -*-
"""vector_store

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17vOF7n-BjGUNLq8_ntnoXKud67YGqr4k
"""


from pathlib import Path
from typing import List, Dict, Any

import numpy as np
import pickle
import faiss


#paths
EMBEDDINGS_PATH = Path("embeddings.npy")
TEXTS_PATH = Path("texts.pkl")
METADATAS_PATH = Path("metadatas.pkl")
INDEX_PATH = Path("faiss_index.bin")


def build_faiss_index() -> None:
    #build and save a FAISS inner-product index from embeddings.npy.
    if not EMBEDDINGS_PATH.exists():
        raise FileNotFoundError(f"Embeddings file not found at {EMBEDDINGS_PATH.resolve()}")

    print(f"[VS] Loading embeddings from {EMBEDDINGS_PATH.resolve()} ...")
    embeddings = np.load(EMBEDDINGS_PATH)

    if embeddings.ndim != 2:
        raise ValueError(f"Embeddings must be 2D, got shape {embeddings.shape}")

    n_docs, dim = embeddings.shape
    print(f"[VS] Embeddings shape: {embeddings.shape} (n_docs={n_docs}, dim={dim})")

    #ensure float32 for FAISS
    if embeddings.dtype != np.float32:
        embeddings = embeddings.astype("float32")

    #FAISS index: inner product (cosine similarity if embeddings are normalized)
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)
    print(f"[VS] FAISS index built with {index.ntotal} vectors.")

    print(f"[VS] Saving index to {INDEX_PATH.resolve()} ...")
    faiss.write_index(index, str(INDEX_PATH))
    print("[VS] Done building FAISS index.")


class VectorStore:
    #simple wrapper around FAISS index + texts + metadatas.

    def __init__(
        self,
        index_path: Path = INDEX_PATH,
        texts_path: Path = TEXTS_PATH,
        metadatas_path: Path = METADATAS_PATH,
    ) -> None:
        if not index_path.exists():
            raise FileNotFoundError(f"FAISS index not found at {index_path.resolve()}")
        if not texts_path.exists():
            raise FileNotFoundError(f"Texts file not found at {texts_path.resolve()}")
        if not metadatas_path.exists():
            raise FileNotFoundError(f"Metadatas file not found at {metadatas_path.resolve()}")

        print(f"[VS] Loading FAISS index from {index_path.resolve()} ...")
        self.index = faiss.read_index(str(index_path))

        print(f"[VS] Loading texts from {texts_path.resolve()} ...")
        with texts_path.open("rb") as f_txt:
            self.texts: List[str] = pickle.load(f_txt)

        print(f"[VS] Loading metadatas from {metadatas_path.resolve()} ...")
        with metadatas_path.open("rb") as f_meta:
            self.metadatas: List[Dict[str, Any]] = pickle.load(f_meta)

        if len(self.texts) != len(self.metadatas) or self.index.ntotal != len(self.texts):
            raise ValueError(
                f"Mismatch between index size ({self.index.ntotal}), "
                f"texts ({len(self.texts)}), and metadatas ({len(self.metadatas)})."
            )

        print(f"[VS] VectorStore ready with {len(self.texts)} entries.")

    def search(self, query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:
        #run a similarity search
        if query_embedding.ndim == 1:
            query_embedding = query_embedding[None, :]

        if query_embedding.dtype != np.float32:
            query_embedding = query_embedding.astype("float32")

        scores, indices = self.index.search(query_embedding, k)
        scores = scores[0]
        indices = indices[0]

        results: List[Dict[str, Any]] = []
        for score, idx in zip(scores, indices):
            if idx < 0:
                continue
            text = self.texts[idx]
            metadata = self.metadatas[idx]
            results.append(
                {
                    "score": float(score),
                    "text": text,
                    "metadata": metadata,
                }
            )

        return results


def main() -> None:
    #build the FAISS index from embeddings.npy
    build_faiss_index()


if __name__ == "__main__":
    main()
