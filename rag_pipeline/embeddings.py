# -*- coding: utf-8 -*-
"""embeddings

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mln_5tlYtHrzTluDYzI6NymWmeym2SS1
"""


from pathlib import Path
from typing import List, Dict, Any
import json
import pickle

import numpy as np
from sentence_transformers import SentenceTransformer


#paths
INGESTED_PATH = Path("ingested_documents.jsonl")
EMBEDDINGS_PATH = Path("embeddings.npy")
TEXTS_PATH = Path("texts.pkl")
METADATAS_PATH = Path("metadatas.pkl")

#recommended model for this project
MODEL_NAME = "BAAI/bge-small-en-v1.5"


def load_ingested_documents(path: Path):
  #load ingested_documents.jsonl and return (texts, metadatas).
    if not path.exists():
        raise FileNotFoundError(f"Ingested JSONL not found at {path.resolve()}")

    texts: List[str] = []
    metadatas: List[Dict[str, Any]] = []

    n_total = 0
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            n_total += 1
            line = line.strip()
            if not line:
                continue
            record = json.loads(line)
            text = record.get("text", "").strip()
            metadata = record.get("metadata", {}) or {}
            if not text:
                continue
            texts.append(text)
            metadatas.append(metadata)

    print(f"[EMBED] Parsed {n_total} lines, loaded {len(texts)} valid documents/chunks.")
    return texts, metadatas


def embed_texts(texts: List[str]) -> np.ndarray:
    #embed a list of texts using BAAI/bge-small-en-v1.5
    if not texts:
        print("[EMBED] No texts to embed. Returning empty array.")
        return np.zeros((0, 0), dtype=np.float32)

    print(f"[EMBED] Loading model: {MODEL_NAME}")
    model = SentenceTransformer(MODEL_NAME)

    print(f"[EMBED] Encoding {len(texts)} texts ...")
    embeddings = model.encode(
        texts,
        batch_size=64,
        normalize_embeddings=True,
        convert_to_numpy=True,
        show_progress_bar=True,
    ).astype("float32")

    print(f"[EMBED] Embeddings shape: {embeddings.shape}")
    return embeddings


def main() -> None:
    #load ingested docs (CSV + PDF chunks)
    texts, metadatas = load_ingested_documents(INGESTED_PATH)

    #embed
    embeddings = embed_texts(texts)

    #save artifacts for vector_store.py
    print(f"[EMBED] Saving embeddings to {EMBEDDINGS_PATH.resolve()}")
    np.save(EMBEDDINGS_PATH, embeddings)

    print(f"[EMBED] Saving texts to {TEXTS_PATH.resolve()}")
    with TEXTS_PATH.open("wb") as f_txt:
        pickle.dump(texts, f_txt)

    print(f"[EMBED] Saving metadatas to {METADATAS_PATH.resolve()}")
    with METADATAS_PATH.open("wb") as f_meta:
        pickle.dump(metadatas, f_meta)

    print("[EMBED] Done.")


if __name__ == "__main__":
    main()
